---
layout: post
title:  "onnx æ¨¡å‹é‡åŒ–"
author: shuai
categories: [ onnx,onnxruntime ]
image: assets/images/9.jpg
---

onnx æ¨¡å‹è½¬æ¢ä¸º fp18,int8 çš„ä»£ç ,åŒ…æ‹¬é™æ€é‡åŒ–å’ŒåŠ¨æ€é‡åŒ–

## é¢„å¤„ç†

ä¸€äº›é‡åŒ–éœ€è¦ä¿æŒ MB å†™ç®—å­ä¸è¢«é‡åŒ–,æˆ–è€…åªé‡åŒ–æŸäº›ç®—å­.è¯¥è„šæœ¬ç”¨äºæ‰“å° onnx æ¨¡å‹é‡Œé¢çš„ç®—å­ç±»å‹:
```py
import onnx,sys

def print_onnx_layers(model_path):
    """
    æ‰“å° ONNX æ¨¡å‹ä¸­æ‰€æœ‰å±‚çš„åç§°
    å‚æ•°:
        model_path (str): ONNX æ¨¡å‹æ–‡ä»¶è·¯å¾„
    """
    # åŠ è½½æ¨¡å‹
    model = onnx.load(model_path)
    
    # éªŒè¯æ¨¡å‹æ ¼å¼
    if not isinstance(model, onnx.ModelProto):
        raise ValueError("Invalid ONNX model format")
    
    # éå†è®¡ç®—å›¾ä¸­çš„æ‰€æœ‰èŠ‚ç‚¹
    print(f"{'Index':<6} {'Layer Name':<40} {'Operator Type':<15}")
    print("-" * 70)
    for i, node in enumerate(model.graph.node):
        layer_name = node.name if node.name else "Unnamed"
        op_type = node.op_type
        # print(node.input)
        print(f"{i:<6} {layer_name:<40} {op_type:<15}    {node.input}")

if __name__ == "__main__":
    # æ›¿æ¢ä¸ºä½ çš„ ONNX æ¨¡å‹è·¯å¾„
    model_path = sys.argv[1]
    
    # æ‰“å°æ¨¡å‹ä¸­çš„æ¯ä¸€å±‚
    print_onnx_layers(model_path)
```

é‡åŒ–å‰å…ˆåšä¸€ä¸‹é¢„å¤„ç†,æœ‰äº›æ¨¡å‹åšé¢„å¤„ç†å¯èƒ½å¤±è´¥,ä¸åšä¹Ÿå¯:`python -m onnxruntime.quantization.preprocess --input models/sv_model/model.onnx --output models/sv_model/model.onnx.opt.onnx
`
## onnx æ¨¡å‹è½¬ fp16:
```py
import onnx
from onnxconverter_common import float16
import sys
import os

DEFAULT_OP_BLOCK_LIST = float16.DEFAULT_OP_BLOCK_LIST+['ArrayFeatureExtractor', 'Binarizer', 'CastMap', 'CategoryMapper', 'DictVectorizer',
                                                       'FeatureVectorizer', 'Imputer', 'LabelEncoder', 'LinearClassifier', 'LinearRegressor',
                                                       'Normalizer', 'OneHotEncoder', 'RandomUniformLike', 'SVMClassifier', 'SVMRegressor', 'Scaler',
                                                       'TreeEnsembleClassifier', 'TreeEnsembleRegressor', 'ZipMap', 'NonMaxSuppression', 'TopK',
                                                       'RoiAlign', 'Resize', 'Range', 'CumSum', 'Min', 'Max', 'Upsample']
DEFAULT_OP_BLOCK_LIST = list(DEFAULT_OP_BLOCK_LIST)
node_block_list = ['/decoder/RandomNormalLike']

# sys.argv[1]æ˜¯å¾…è½¬æ¢çš„ onnx æ¨¡å‹
model = onnx.load(sys.argv[1])
model_fp16 = float16.convert_float_to_float16(
    model, keep_io_types=True, op_block_list=DEFAULT_OP_BLOCK_LIST, node_block_list=node_block_list)

print(node_block_list)
onnx.save(model_fp16, sys.argv[1]+"-fp16.onnx")

```

## onnx ä½¿ç”¨ int8 åŠ¨æ€é‡åŒ–

é‡åŒ–ç±»å‹é€‰æ‹© QInt8 æ—¶,,å¯èƒ½å‡ºç°é‡åŒ–åçš„æ¨¡å‹æ— æ³•è¿è¡Œçš„é—®é¢˜,ä¼¼ä¹ä¸»è¦æ˜¯ conv å¼•èµ·çš„,æ­¤æ—¶é‡åŒ–ç±»å‹æ”¹ä¸ºQInt8
```py
import onnx,sys
from onnxruntime.quantization import quantize_dynamic, QuantType

def dynamic_quantization(input_model_path, output_model_path):
    """
    å¯¹ONNXæ¨¡å‹è¿›è¡ŒåŠ¨æ€INT8é‡åŒ–
    
    å‚æ•°:
        input_model_path: åŸå§‹FP32æ¨¡å‹è·¯å¾„
        output_model_path: é‡åŒ–åINT8æ¨¡å‹ä¿å­˜è·¯å¾„
    """
    # åŠ è½½åŸå§‹æ¨¡å‹éªŒè¯
    original_model = onnx.load(input_model_path)
    onnx.checker.check_model(original_model)
    print(f"âœ… åŸå§‹æ¨¡å‹éªŒè¯é€šè¿‡: {input_model_path}")
    
    # æ‰§è¡ŒåŠ¨æ€é‡åŒ–
    quantize_dynamic(
        input_model_path,          # è¾“å…¥æ¨¡å‹è·¯å¾„
        output_model_path,         # è¾“å‡ºæ¨¡å‹è·¯å¾„
        # op_types_to_quantize=['MatMul', 'Attention', 'LSTM', 'Gather', 'Transpose', 'EmbedLayerNormalization'],
        nodes_to_exclude=['Conv','Mul'],
        # activation_type=QuantType.QUInt8,  # æ¿€æ´»å€¼é‡åŒ–ç±»å‹
        weight_type=QuantType.QUInt8,       # æƒé‡é‡åŒ–ç±»å‹
        per_channel=False,         # æ˜¯å¦ä½¿ç”¨é€é€šé“é‡åŒ–
        reduce_range=False,        # æ˜¯å¦å‡å°‘é‡åŒ–èŒƒå›´(æŸäº›CPUéœ€è¦)
        use_external_data_format=False,  # æ˜¯å¦ä½¿ç”¨å¤–éƒ¨æ•°æ®æ ¼å¼(å¤§å‹æ¨¡å‹éœ€è¦)
        # optimize_model=True        # é‡åŒ–å‰ä¼˜åŒ–æ¨¡å‹
    )
    
    print(f"ğŸš€ åŠ¨æ€é‡åŒ–å®Œæˆ! é‡åŒ–æ¨¡å‹å·²ä¿å­˜è‡³: {output_model_path}")

if __name__ == "__main__":
    # ä½¿ç”¨ç¤ºä¾‹
    input_model = sys.argv[1]  # æ›¿æ¢ä¸ºä½ çš„æ¨¡å‹è·¯å¾„
    output_model = sys.argv[1]+".int8.onnx"  # é‡åŒ–æ¨¡å‹è¾“å‡ºè·¯å¾„
    
    dynamic_quantization(input_model, output_model)

```

## int8 é™æ€é‡åŒ–

ä»¥ä¸‹ä»£ç åŒæ—¶å±•ç¤ºäº†å¦‚ä½•æ„é€ æ ¡å‡†æ•°æ®é›†:
```py
# python -m onnxruntime.quantization.preprocess --input models/sv_model/model.onnx --output models/sv_model/model.onnx.opt.onnx

import librosa
import numpy as np
import glob,os,sys,torchaudio
from onnxruntime.quantization import quantize_static, CalibrationMethod, QuantFormat, QuantType
try:
    from speakerlab.process.processor import FBank
except ImportError:
    sys.path.append('./export')
    from speakerlab.process.processor import FBank
feature_extractor_no_men = FBank(80, sample_rate=16000, mean_nor=False)
def load_wav(wav_file, obj_fs=16000):
    wav, fs = torchaudio.load(wav_file)
    if fs != obj_fs:
        print(f'[WARNING]: The sample rate of {wav_file} is not {obj_fs}, resample it.')
        wav, fs = torchaudio.sox_effects.apply_effects_tensor(
            wav, fs, effects=[['rate', str(obj_fs)]]
        )
    if wav.shape[0] > 1:
        wav = wav[0, :].unsqueeze(0)
    return wav

# è¿™é‡Œå‡†å¤‡çš„æ ¡å‡†æ•°æ®é›†åªéœ€è¦å‡†å¤‡è¾“å…¥å°±è¡Œäº†
def create_audio_calibration_dataset(audio_dir, num_samples=100):
    """
    åˆ›å»ºéŸ³é¢‘æ¨¡å‹çš„æ ¡å‡†æ•°æ®é›†
    
    å‚æ•°:
        audio_dir: éŸ³é¢‘æ–‡ä»¶ç›®å½•
        num_samples: æ ·æœ¬æ•°é‡
    """
    all_files = glob.glob(os.path.join(audio_dir, "*.wav"))
    selected_files = np.random.choice(all_files, num_samples, replace=True)
    
    calibration_data = []
    for file_path in selected_files:
        # åŠ è½½éŸ³é¢‘å¹¶æå–ç‰¹å¾
        wav=load_wav(file_path)
        # print("====",file_path)
        feat_no_mean = feature_extractor_no_men(wav).unsqueeze(0).numpy().astype(np.float32)
        calibration_data.append(feat_no_mean)  # è½¬ç½®ä¸ºæ—¶é—´åºåˆ—
    
    return calibration_data


def static_quantization(model_path, quantized_model_path, calibration_dataset):
    """
    æ‰§è¡Œé™æ€é‡åŒ–
    
    å‚æ•°:
        model_path: åŸå§‹ONNXæ¨¡å‹è·¯å¾„
        quantized_model_path: é‡åŒ–æ¨¡å‹ä¿å­˜è·¯å¾„
        calibration_dataset: æ ¡å‡†æ•°æ®é›†
    """
    # åˆ›å»ºæ ¡å‡†æ•°æ®è¯»å–å™¨
    class CalibrationDataReader:
        def __init__(self, data_list):
            self.data = data_list
            self.index = 0
            
        def get_next(self):
            if self.index < len(self.data):
                # æ³¨æ„ï¼š'input_0' åº”æ›¿æ¢ä¸ºæ¨¡å‹çš„è¾“å…¥èŠ‚ç‚¹åç§°
                input_data = {"feat": self.data[self.index]}  
                self.index += 1
                return input_data
            return None
        
        def rewind(self):
            self.index = 0

    # æ‰§è¡Œé™æ€é‡åŒ–
    quantize_static(
        model_input=model_path,
        model_output=quantized_model_path,
        calibration_data_reader=CalibrationDataReader(calibration_dataset),
        # op_types_to_quantize=['Conv','Mul',"AveragePool","BatchNormalization","ReduceMean",],
        op_types_to_quantize=['Conv','Mul'],
        quant_format=QuantFormat.QOperator,  # é‡åŒ–æ ¼å¼
        activation_type=QuantType.QInt8,     # æ¿€æ´»å€¼é‡åŒ–ç±»å‹
        weight_type=QuantType.QInt8,         # æƒé‡é‡åŒ–ç±»å‹
        calibrate_method=CalibrationMethod.MinMax,  # æ ¡å‡†æ–¹æ³•
        extra_options = {"ExtraSymmetric": True}    # é¢å¤–é€‰é¡¹
    )
# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # 1. å‡†å¤‡æ ¡å‡†æ•°æ®é›†
    calibration_data = create_audio_calibration_dataset("./", 100)
    
    # 2. æ‰§è¡Œé™æ€é‡åŒ–
    static_quantization(
        "models/sv_model/model.onnx",
        "models/sv_model/model.onnx.sint8.onnx",
        calibration_data
    )
```

éœ€è¦æ³¨æ„çš„æ˜¯,æœ€å¥½æŒ‡å®šé‡åŒ–çš„ç®—å­ç±»å‹,ä¸Šé¢çš„ demoé‡Œé¢,é¢å¤–æŒ‡å®šäº†"AveragePool","BatchNormalization","ReduceMean"ç®—å­,é€Ÿåº¦ä¸ä»…æ²¡æœ‰æå‡,è¿˜ç¨å¾®æœ‰äº›ä¸‹é™.
è‡³äºé‡åŒ–æ ¼å¼,å¯ä»¥é€‰æ‹© QDQ å’ŒQOperator,QDQæ˜¯å’Œåœ¨ x86 æœåŠ¡å™¨ä¸Š,QOperatoré€‚åˆåœ¨ arm ç«¯ä¾§è®¾å¤‡ä¸Š.
å¦å¤–é‡åŒ–ç±»å‹ä¹Ÿå¯¹é€Ÿåº¦æœ‰è¾ƒå¤§çš„å½±å“,åœ¨ arm ç«¯ä¾§è®¾å¤‡ä¸Šä½¿ç”¨ QInt8 ç›¸æ¯” QUInt8 æœ‰çº¦ 20%æå‡;è€Œåœ¨ x86 çš„ linux ä¸Šä½¿ç”¨ QInt8 ç›¸æ¯” QUInt8 æœ‰å¥½å‡ å€çš„æå‡,ä¸»è¦æ˜¯ QUInt8 é€Ÿåº¦æ¯”ä¸é‡åŒ–æ…¢äº†å¥½å‡ å€.
ä»¥ä¸Šä¸»è¦æ˜¯çœ‹æ¨ç†é€Ÿåº¦è¿™ä¸€æŒ‡æ ‡,å¹¶æ²¡æœ‰è€ƒè™‘å‡†ç¡®æ€§,å®é™…ä½¿ç”¨æ—¶è¿˜è¦è€ƒè™‘é‡åŒ–è¯¯å·®,ç»¼åˆæ¥é€‰æ‹©.